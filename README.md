# Proyecto de ClasificaciÃ³n de Aves - CUB-200-2011

Este proyecto implementa la clasificaciÃ³n automatizada de 200 especies de aves del dataset CUB-200-2011 mediante tÃ©cnicas de Deep Learning. Se desarrollaron y compararon tres modelos diferentes para evaluar su rendimiento en la tarea de clasificaciÃ³n.

## ğŸ“‹ DescripciÃ³n del Proyecto

El objetivo principal es clasificar automÃ¡ticamente 200 especies de aves utilizando el dataset Caltech-UCSD Birds-200-2011 (CUB-200-2011). Se implementaron tres arquitecturas de redes neuronales:

1. **CNN Base**: Una red neuronal convolucional construida desde cero
2. **ResNet50**: Modelo pre-entrenado con Transfer Learning y Fine-tuning
3. **EfficientNetB0**: Modelo pre-entrenado con Transfer Learning y Fine-tuning

### TÃ©cnicas Implementadas

- **Transfer Learning**: Aprovechamiento de modelos pre-entrenados en ImageNet
- **Fine-tuning**: Ajuste fino de las Ãºltimas capas de los modelos pre-entrenados
- **Data Augmentation**: Aumento de datos para mejorar la generalizaciÃ³n
- **Early Stopping**: DetenciÃ³n temprana para evitar sobreajuste
- **ReduceLROnPlateau**: ReducciÃ³n adaptativa de la tasa de aprendizaje

## ğŸ—ï¸ Estructura del Proyecto

```
Proyecto-Lorena-CUB-200-2011/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ base_cnn.py           # CNN base desde cero
â”‚   â”‚   â”œâ”€â”€ resnet50_model.py     # ResNet50 con Transfer Learning
â”‚   â”‚   â””â”€â”€ efficientnet_model.py # EfficientNetB0 con Transfer Learning
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ data_utils.py         # Carga y preprocesamiento de datos
â”‚       â”œâ”€â”€ training_utils.py     # Utilidades de entrenamiento y callbacks
â”‚       â””â”€â”€ visualization.py      # VisualizaciÃ³n de resultados
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train/                    # ImÃ¡genes de entrenamiento
â”‚   â”œâ”€â”€ val/                      # ImÃ¡genes de validaciÃ³n
â”‚   â””â”€â”€ test/                     # ImÃ¡genes de prueba
â”œâ”€â”€ notebooks/                    # Jupyter notebooks para anÃ¡lisis
â”œâ”€â”€ saved_models/                 # Modelos entrenados guardados
â”œâ”€â”€ results/                      # GrÃ¡ficos y resultados
â”œâ”€â”€ train.py                      # Script principal de entrenamiento
â””â”€â”€ requirements.txt              # Dependencias del proyecto
```

## ğŸš€ InstalaciÃ³n

### Prerequisitos

- Python 3.8 o superior
- pip (gestor de paquetes de Python)
- GPU con CUDA (recomendado para entrenamiento)

### Pasos de InstalaciÃ³n

1. Clonar el repositorio:
```bash
git clone https://github.com/Dmgg00/Proyecto-Lorena-CUB-200-2011.git
cd Proyecto-Lorena-CUB-200-2011
```

2. Instalar las dependencias:
```bash
pip install -r requirements.txt
```

3. Descargar el dataset CUB-200-2011:
   - Descargar desde [Caltech-UCSD Birds-200-2011](http://www.vision.caltech.edu/datasets/cub_200_2011/)
   - Extraer y organizar las imÃ¡genes en las carpetas `data/train/`, `data/val/` y `data/test/`

## ğŸ“Š Dataset

El dataset CUB-200-2011 contiene:
- **200 categorÃ­as** de especies de aves
- **11,788 imÃ¡genes** en total
- ImÃ¡genes con variedad en pose, iluminaciÃ³n y fondo
- Anotaciones detalladas (no utilizadas en este proyecto bÃ¡sico)

### OrganizaciÃ³n de Datos

Las imÃ¡genes deben estar organizadas en la siguiente estructura:
```
data/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ clase_001/
â”‚   â”‚   â”œâ”€â”€ imagen1.jpg
â”‚   â”‚   â””â”€â”€ imagen2.jpg
â”‚   â”œâ”€â”€ clase_002/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ val/
â”‚   â””â”€â”€ (misma estructura)
â””â”€â”€ test/
    â””â”€â”€ (misma estructura)
```

## ğŸ¯ Uso

### Entrenamiento de Modelos

Para entrenar los tres modelos y compararlos:

```bash
python train.py
```

Este script ejecutarÃ¡:
1. Entrenamiento de la CNN base (desde cero)
2. Entrenamiento de ResNet50 con Transfer Learning y Fine-tuning
3. Entrenamiento de EfficientNetB0 con Transfer Learning y Fine-tuning
4. ComparaciÃ³n de resultados
5. GeneraciÃ³n de grÃ¡ficos y mÃ©tricas

### Uso de Modelos Individuales

#### CNN Base
```python
from src.models.base_cnn import create_base_cnn

model = create_base_cnn(input_shape=(224, 224, 3), num_classes=200)
```

#### ResNet50
```python
from src.models.resnet50_model import create_resnet50_model, unfreeze_model

# Crear modelo
model = create_resnet50_model(input_shape=(224, 224, 3), num_classes=200)

# Entrenar capas superiores primero, luego aplicar fine-tuning
model = unfreeze_model(model, trainable_layers=50)
```

#### EfficientNetB0
```python
from src.models.efficientnet_model import create_efficientnet_model, unfreeze_efficientnet

# Crear modelo
model = create_efficientnet_model(input_shape=(224, 224, 3), num_classes=200)

# Entrenar capas superiores primero, luego aplicar fine-tuning
model = unfreeze_efficientnet(model, unfreeze_from=100)
```

## ğŸ” Modelos Implementados

### 1. CNN Base (Desde Cero)

Arquitectura personalizada con:
- 4 bloques convolucionales con BatchNormalization
- MaxPooling y Dropout para regularizaciÃ³n
- Capas densas con 512 y 256 neuronas
- Total: ~10M parÃ¡metros entrenables

### 2. ResNet50 (Transfer Learning)

- Base: ResNet50 pre-entrenada en ImageNet
- Capas personalizadas: GlobalAveragePooling + Dense layers
- Fine-tuning de las Ãºltimas 50 capas
- Optimizador: Adam con learning rate adaptativo

### 3. EfficientNetB0 (Transfer Learning)

- Base: EfficientNetB0 pre-entrenada en ImageNet
- Capas personalizadas: GlobalAveragePooling + Dense layers
- Fine-tuning de las Ãºltimas 100+ capas
- Optimizador: Adam con learning rate adaptativo

## ğŸ“ˆ Resultados Esperados

Los modelos de Transfer Learning (ResNet50 y EfficientNetB0) demostraron ser superiores en:
- **Mayor precisiÃ³n** en el conjunto de validaciÃ³n y prueba
- **Menor pÃ©rdida** durante el entrenamiento
- **Convergencia mÃ¡s rÃ¡pida** comparado con la CNN base
- **Mejor generalizaciÃ³n** gracias al conocimiento pre-entrenado

### Callbacks Utilizados

1. **Early Stopping**
   - Monitor: val_loss
   - Paciencia: 10 Ã©pocas
   - Restaura los mejores pesos

2. **ReduceLROnPlateau**
   - Monitor: val_loss
   - Factor de reducciÃ³n: 0.5
   - Paciencia: 5 Ã©pocas

3. **ModelCheckpoint**
   - Guarda el mejor modelo segÃºn val_accuracy

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- **TensorFlow/Keras**: Framework de Deep Learning
- **NumPy**: ComputaciÃ³n numÃ©rica
- **Pandas**: ManipulaciÃ³n de datos
- **Matplotlib/Seaborn**: VisualizaciÃ³n
- **Scikit-learn**: MÃ©tricas y preprocesamiento
- **Pillow**: Procesamiento de imÃ¡genes

## ğŸ“ Notas

- El entrenamiento puede tomar varias horas dependiendo del hardware
- Se recomienda usar GPU para acelerar el entrenamiento
- Los modelos pre-entrenados se descargan automÃ¡ticamente la primera vez
- Los checkpoints se guardan en `saved_models/`
- Los grÃ¡ficos se guardan en `results/`

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Por favor:
1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## ğŸ“„ Licencia

Este proyecto es de cÃ³digo abierto y estÃ¡ disponible para fines educativos.

## ğŸ‘¥ Autor

- Proyecto Lorena - ClasificaciÃ³n de Aves CUB-200-2011

## ğŸ™ Agradecimientos

- Dataset CUB-200-2011 por Caltech-UCSD
- Comunidad de TensorFlow y Keras
- Investigadores de Transfer Learning y arquitecturas de CNN